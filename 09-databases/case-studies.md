# Database Case Studies

> *"Data is the new oil. And like oil, it's valuable, but if unrefined, it cannot really be used."* â€” Clive Humby
>
> *Also like oil, it can cause massive explosions if handled incorrectly.*

---

## Case Study 1: The Great DynamoDB-to-Cosmos Migration ğŸš€

### The Setup

**Company:** StreamFlix (fictional)
**Challenge:** Migrate from DynamoDB to Cosmos DB without users noticing
**Scale:** 50M users, 10B requests/day, 50TB data
**Constraint:** Zero downtime (streaming service, remember?)

### Why They Switched

```
The Conversation That Started It All:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CTO: "We're going all-in on Azure for our new AI features."
DBA: "Cool. What about our DynamoDB tables?"
CTO: "Move them to Cosmos DB."
DBA: "All 47 of them?"
CTO: "Yes."
DBA: "With zero downtime?"
CTO: "Obviously."
DBA: *internal screaming* "Challenge accepted."
```

### The Migration Strategy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DUAL-WRITE MIGRATION PATTERN                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  PHASE 1: Setup (Week 1-2)                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  â€¢ Provision Cosmos DB with same capacity planning                    â”‚   â”‚
â”‚  â”‚  â€¢ Create matching containers (partition key strategy!)               â”‚   â”‚
â”‚  â”‚  â€¢ Set up Azure Data Factory for initial sync                        â”‚   â”‚
â”‚  â”‚  â€¢ Deploy dual-write application layer                               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  PHASE 2: Historical Migration (Week 2-3)                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚   DynamoDB â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Azure Data Factory                        â”‚   â”‚
â”‚  â”‚   (50TB)                         â”‚                                    â”‚   â”‚
â”‚  â”‚                                  â”‚ Parallel pipelines                â”‚   â”‚
â”‚  â”‚                                  â”‚ 1M docs/minute                    â”‚   â”‚
â”‚  â”‚                                  â–¼                                    â”‚   â”‚
â”‚  â”‚                            Cosmos DB                                  â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚   Time: 72 hours                                                     â”‚   â”‚
â”‚  â”‚   Cost: $12,000 in throughput (worth it)                            â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  PHASE 3: Dual-Write (Week 3-4)                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚   Application                                                         â”‚   â”‚
â”‚  â”‚       â”‚                                                               â”‚   â”‚
â”‚  â”‚       â”œâ”€â”€â”€â”€â”€â”€â–º DynamoDB (Primary reads/writes)                       â”‚   â”‚
â”‚  â”‚       â”‚                                                               â”‚   â”‚
â”‚  â”‚       â””â”€â”€â”€â”€â”€â”€â–º Cosmos DB (Shadow writes, validation reads)           â”‚   â”‚
â”‚  â”‚                     â”‚                                                 â”‚   â”‚
â”‚  â”‚                     â–¼                                                 â”‚   â”‚
â”‚  â”‚               Compare results                                         â”‚   â”‚
â”‚  â”‚               Log discrepancies                                       â”‚   â”‚
â”‚  â”‚               Alert if mismatch > 0.01%                              â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  PHASE 4: Cutover (Week 5)                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚   Feature flag: COSMOS_PRIMARY = true                                 â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚   Gradual rollout:                                                    â”‚   â”‚
â”‚  â”‚   â€¢ 1% traffic  â†’ Monitor for 4 hours                                â”‚   â”‚
â”‚  â”‚   â€¢ 10% traffic â†’ Monitor for 8 hours                                â”‚   â”‚
â”‚  â”‚   â€¢ 50% traffic â†’ Monitor for 24 hours                               â”‚   â”‚
â”‚  â”‚   â€¢ 100% traffic â†’ ğŸ‰                                                 â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚   Rollback plan: Flip flag, < 30 seconds                             â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The Partition Key Puzzle

Their biggest challenge? Partition key design.

```
DynamoDB Design:                    Cosmos DB Design:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Table: user_watch_history           Container: watchHistory
PK: userId                          Partition Key: /userId
SK: timestamp
                                    Problem: Hot partition!
                                    User "binge_watcher_9000" has
                                    500K documents, causing throttling

Solution:
â”€â”€â”€â”€â”€â”€â”€â”€â”€

// Before: Simple userId partition
{
  "userId": "user123",
  "movieId": "movie456",
  "timestamp": "2024-01-15T..."
}

// After: Synthetic partition key
{
  "userId": "user123",
  "partitionKey": "user123_2024-01",  // userId + month
  "movieId": "movie456",
  "timestamp": "2024-01-15T..."
}

// Query pattern adjusted:
// Instead of: WHERE userId = 'user123'
// Now: WHERE partitionKey IN ('user123_2024-01', 'user123_2023-12', ...)
```

### Results

| Metric | DynamoDB | Cosmos DB | Verdict |
|--------|----------|-----------|---------|
| P99 Latency | 15ms | 8ms | ğŸ† Cosmos |
| Cost (comparable workload) | $45K/month | $38K/month | ğŸ† Cosmos |
| Global distribution | 3 regions | 5 regions | ğŸ† Cosmos |
| Migration downtime | â€” | 0 seconds | ğŸ‰ |

---

## Case Study 2: When SQL Server Met Azure (A Love Story) ğŸ’™

### The Setup

**Company:** FinanceFirst Bank (fictional)
**Situation:** 15-year-old SQL Server estate, 200+ databases
**Goal:** Modernize without breaking anything (banks hate broken things)

### The Database Landscape

```
DISCOVERY PHASE RESULTS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Total Databases: 247

By Size:
â”œâ”€â”€ < 100 GB: 180 databases
â”œâ”€â”€ 100 GB - 1 TB: 52 databases
â”œâ”€â”€ 1 TB - 5 TB: 12 databases
â””â”€â”€ > 5 TB: 3 databases (the scary ones)

By Criticality:
â”œâ”€â”€ Tier 1 (Core Banking): 15 databases
â”œâ”€â”€ Tier 2 (Customer Facing): 45 databases
â”œâ”€â”€ Tier 3 (Internal Apps): 87 databases
â””â”€â”€ Tier 4 (Nobody knows): 100 databases ğŸ¤·

By SQL Version:
â”œâ”€â”€ SQL Server 2019: 50
â”œâ”€â”€ SQL Server 2017: 80
â”œâ”€â”€ SQL Server 2016: 70
â”œâ”€â”€ SQL Server 2012: 40 (uh oh)
â””â”€â”€ SQL Server 2008: 7 (WHY?!)
```

### The Decision Framework

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATABASE MODERNIZATION DECISION TREE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   Start Here                                                                 â”‚
â”‚       â”‚                                                                      â”‚
â”‚       â–¼                                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚   â”‚ Does it use SQL Server-specific features?â”‚                               â”‚
â”‚   â”‚ (Linked servers, CLR, Service Broker)   â”‚                               â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                    â”‚                                                         â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”                                                â”‚
â”‚          â”‚                 â”‚                                                â”‚
â”‚         YES               NO                                                â”‚
â”‚          â”‚                 â”‚                                                â”‚
â”‚          â–¼                 â–¼                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚   â”‚ SQL Managed â”‚   â”‚ Need instance-level control?â”‚                        â”‚
â”‚   â”‚ Instance    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚                                        â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                          â”‚                   â”‚                              â”‚
â”‚                         YES                 NO                              â”‚
â”‚                          â”‚                   â”‚                              â”‚
â”‚                          â–¼                   â–¼                              â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚                   â”‚ SQL Managed â”‚     â”‚ Size > 4TB or need  â”‚              â”‚
â”‚                   â”‚ Instance    â”‚     â”‚ 100+ DTU equivalent?â”‚              â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                  â”‚                          â”‚
â”‚                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚                                        â”‚                   â”‚                â”‚
â”‚                                       YES                 NO                â”‚
â”‚                                        â”‚                   â”‚                â”‚
â”‚                                        â–¼                   â–¼                â”‚
â”‚                                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚                                 â”‚ SQL DB      â”‚     â”‚ SQL DB      â”‚        â”‚
â”‚                                 â”‚ Hyperscale  â”‚     â”‚ Standard    â”‚        â”‚
â”‚                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The Migration Waves

**Wave 1: Low-Risk Wins (Month 1-2)**
```
Target: Tier 4 databases (the "nobody knows" ones)
Method: Azure Database Migration Service
Result: 87 databases migrated
Surprises: 12 databases actually were important
Learning: Always validate with app owners
```

**Wave 2: Internal Apps (Month 3-4)**
```
Target: Tier 3 databases
Method: Online migration with DMS
Downtime: < 5 minutes per database
Fun fact: Found 15 databases with no connections in 2 years
         (Deleted them, nobody noticed)
```

**Wave 3: Customer Facing (Month 5-6)**
```
Target: Tier 2 databases
Method: Transactional replication + cutover
Downtime: < 30 seconds (maintenance window)
Stress level: Medium-High
Coffee consumed: Excessive
```

**Wave 4: Core Banking (Month 7-8)**
```
Target: Tier 1 databases (15 most critical)
Method: SQL Managed Instance with Link
Downtime: Zero (real-time sync, instant failover)
Regulatory approval: Required and obtained
Backup plans: Had backup plans for our backup plans
```

### Cost Optimization Post-Migration

```
BEFORE: On-Premises
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ 12 physical servers: $180K/year (hardware refresh)
â€¢ SQL licenses: $400K/year
â€¢ Data center costs: $150K/year
â€¢ DBA overtime: Priceless (actually $80K)
â€¢ Total: ~$810K/year

AFTER: Azure
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ SQL Managed Instance (Tier 1): $15K/month
â€¢ SQL Database (Tier 2-3): $20K/month
â€¢ Hyperscale (Big DBs): $8K/month
â€¢ Reserved capacity (3-year): -40%
â€¢ Total: ~$310K/year

SAVINGS: $500K/year ğŸ’°
ROI: < 1 year
DBA sleep quality: Significantly improved
```

---

## Case Study 3: The Real-Time Analytics Adventure ğŸ“Š

### The Setup

**Company:** GameStream (fictional)
**Challenge:** Real-time analytics for 100M gaming events/second
**Requirements:**
- Sub-second query latency
- 90-day hot data retention
- 7-year cold data retention
- Multi-region for global players

### The Architecture Evolution

```
VERSION 1 (The NaÃ¯ve Approach):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Everything in Cosmos DB!

Result:
â€¢ Cost: $150K/month ğŸ’¸
â€¢ Query latency: 200ms-2s (too slow)
â€¢ Aggregations: Painful
â€¢ Finance team: Unhappy

VERSION 2 (The Overengineered Approach):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Lambda architecture with everything!
â€¢ Kafka â†’ Cosmos DB (hot)
â€¢ Kafka â†’ Spark â†’ Azure SQL (warm)
â€¢ Spark â†’ Data Lake (cold)
â€¢ Synapse for analytics

Result:
â€¢ Cost: $80K/month
â€¢ Complexity: ğŸ¤¯
â€¢ Operational overhead: 3 FTEs
â€¢ Time to debug issues: Days

VERSION 3 (The "Why Didn't We Do This First" Approach):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Azure Data Explorer (ADX) for the win!
```

### The Winning Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    REAL-TIME GAMING ANALYTICS                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   Game Servers (Global)                                                      â”‚
â”‚   100M events/second                                                         â”‚
â”‚         â”‚                                                                    â”‚
â”‚         â–¼                                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                      Event Hubs (Partitioned)                        â”‚   â”‚
â”‚   â”‚                      100 partitions, 20 TUs                          â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                                                                    â”‚
â”‚         â”‚ Streaming ingestion                                                â”‚
â”‚         â–¼                                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                    Azure Data Explorer (ADX)                         â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚   â”‚   â”‚  HOT CACHE (SSD)           â”‚  COLD STORAGE (Blob)           â”‚   â”‚   â”‚
â”‚   â”‚   â”‚  Last 7 days               â”‚  8-90 days                     â”‚   â”‚   â”‚
â”‚   â”‚   â”‚  Sub-second queries        â”‚  Seconds to query              â”‚   â”‚   â”‚
â”‚   â”‚   â”‚  High cost per GB          â”‚  Low cost per GB               â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â”‚   Cluster: 16 nodes, D14_v2                                         â”‚   â”‚
â”‚   â”‚   Ingestion: 100M events/sec sustained                              â”‚   â”‚
â”‚   â”‚   Query latency: P95 < 500ms                                        â”‚   â”‚
â”‚   â”‚                                                                      â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                                                                    â”‚
â”‚         â”‚ Continuous export (90+ days)                                      â”‚
â”‚         â–¼                                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                    Data Lake Gen2 (Archive)                          â”‚   â”‚
â”‚   â”‚                    Parquet format, 7-year retention                  â”‚   â”‚
â”‚   â”‚                    Query via Synapse Serverless                      â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚   DASHBOARDS                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚   â”‚ Grafana       â”‚  â”‚ Power BI      â”‚  â”‚ Custom React  â”‚                  â”‚
â”‚   â”‚ (Operations)  â”‚  â”‚ (Business)    â”‚  â”‚ (Players)     â”‚                  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Sample Queries

```kusto
// Real-time player count by region (sub-second)
GameEvents
| where Timestamp > ago(5m)
| where EventType == "PlayerActive"
| summarize ActivePlayers = dcount(PlayerId) by Region
| order by ActivePlayers desc

// Revenue by game mode (last 24 hours)
Transactions
| where Timestamp > ago(24h)
| summarize Revenue = sum(Amount) by GameMode
| render piechart

// Anomaly detection (cheating?)
GameEvents
| where Timestamp > ago(1h)
| where EventType == "Kill"
| summarize Kills = count() by PlayerId
| where Kills > 100  // Probably cheating
| project PlayerId, Kills, Suspicion = "HIGH"
```

### Results

| Metric | Before (Lambda) | After (ADX) |
|--------|-----------------|-------------|
| Monthly cost | $80K | $35K |
| Query latency (P95) | 2-5 seconds | 300ms |
| Operational FTEs | 3 | 0.5 |
| Time to new dashboard | 1-2 weeks | 1-2 hours |
| Developer happiness | ğŸ˜« | ğŸ˜Š |

---

## Case Study 4: The Multi-Model Database Dilemma ğŸ¤”

### The Setup

**Company:** HealthTech (fictional)
**Challenge:** Different data types, different access patterns, one platform

### The Data Diversity

```
DATA TYPES IN THE SYSTEM:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

1. Patient Records (Relational)
   â€¢ HIPAA compliance required
   â€¢ Complex joins across tables
   â€¢ Audit trail mandatory
   â€¢ Volume: 50M patients

2. Medical Images (Binary/Blob)
   â€¢ X-rays, MRIs, CT scans
   â€¢ Large files (50MB - 2GB)
   â€¢ Metadata queries needed
   â€¢ Volume: 500TB

3. IoT Sensor Data (Time-series)
   â€¢ Heart monitors, glucose sensors
   â€¢ High-frequency (1000 samples/sec/device)
   â€¢ 30-day hot, 7-year archive
   â€¢ Volume: 10B samples/day

4. Doctor Notes (Document)
   â€¢ Unstructured text
   â€¢ Full-text search needed
   â€¢ Version history
   â€¢ Volume: 100M documents

5. Patient Relationships (Graph)
   â€¢ Family history
   â€¢ Treatment pathways
   â€¢ Doctor-patient relationships
   â€¢ Complex traversals
```

### The Multi-Database Solution

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    POLYGLOT PERSISTENCE ARCHITECTURE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚                        API LAYER (FHIR Compliant)                      â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                    â”‚                                         â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚         â”‚              â”‚           â”‚           â”‚              â”‚            â”‚
â”‚         â–¼              â–¼           â–¼           â–¼              â–¼            â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚ Azure SQL â”‚  â”‚ Blob +    â”‚ â”‚  ADX  â”‚ â”‚ Cosmos DB â”‚ â”‚ Cosmos DB â”‚      â”‚
â”‚   â”‚ (HIPAA)   â”‚  â”‚ Cognitive â”‚ â”‚       â”‚ â”‚ (Document)â”‚ â”‚ (Gremlin) â”‚      â”‚
â”‚   â”‚           â”‚  â”‚ Search    â”‚ â”‚       â”‚ â”‚           â”‚ â”‚           â”‚      â”‚
â”‚   â”‚ Patient   â”‚  â”‚           â”‚ â”‚ IoT   â”‚ â”‚ Notes     â”‚ â”‚ Graph     â”‚      â”‚
â”‚   â”‚ Records   â”‚  â”‚ Medical   â”‚ â”‚ Data  â”‚ â”‚           â”‚ â”‚           â”‚      â”‚
â”‚   â”‚           â”‚  â”‚ Images    â”‚ â”‚       â”‚ â”‚           â”‚ â”‚           â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                                              â”‚
â”‚   WHY EACH CHOICE:                                                          â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                         â”‚
â”‚   â€¢ SQL: ACID transactions, complex queries, mature compliance tooling     â”‚
â”‚   â€¢ Blob + Search: Cost-effective large file storage + metadata queries    â”‚
â”‚   â€¢ ADX: Purpose-built for time-series, compression, fast aggregations    â”‚
â”‚   â€¢ Cosmos (Doc): Flexible schema, global distribution for mobile apps    â”‚
â”‚   â€¢ Cosmos (Gremlin): Native graph traversal for relationship queries     â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Integration Pattern

```csharp
// Unified Patient Context Service

public class PatientService
{
    private readonly SqlConnection _sqlDb;
    private readonly CosmosClient _cosmosClient;
    private readonly DataExplorerClient _adxClient;

    public async Task<PatientContext> GetFullPatientContext(string patientId)
    {
        // Parallel fetch from all databases
        var tasks = new[]
        {
            GetDemographicsAsync(patientId),      // SQL
            GetRecentNotesAsync(patientId),       // Cosmos Document
            GetVitalHistoryAsync(patientId),      // ADX
            GetFamilyHistoryAsync(patientId),     // Cosmos Gremlin
            GetImageMetadataAsync(patientId)      // Cognitive Search
        };

        await Task.WhenAll(tasks);

        return new PatientContext
        {
            Demographics = await tasks[0],
            RecentNotes = await tasks[1],
            VitalHistory = await tasks[2],
            FamilyHistory = await tasks[3],
            Images = await tasks[4]
        };
    }
}
```

### Lessons Learned

| Lesson | Details |
|--------|---------|
| **Use the right tool** | Don't force SQL for everything |
| **Plan for integration** | API layer abstracts complexity |
| **Consider operations** | More databases = more to manage |
| **Think about consistency** | Cross-database transactions are hard |
| **Security uniformly** | One identity, one audit trail |

---

## Summary: Database Selection Cheat Sheet

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WHEN TO USE WHAT                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  Azure SQL Database                                                          â”‚
â”‚  âœ“ Complex transactions                                                     â”‚
â”‚  âœ“ Existing SQL Server apps                                                 â”‚
â”‚  âœ“ Regulatory compliance                                                    â”‚
â”‚  âœ“ Complex reporting                                                        â”‚
â”‚                                                                              â”‚
â”‚  Cosmos DB                                                                   â”‚
â”‚  âœ“ Global distribution needed                                               â”‚
â”‚  âœ“ Variable/flexible schema                                                 â”‚
â”‚  âœ“ High write throughput                                                    â”‚
â”‚  âœ“ Low latency at scale                                                     â”‚
â”‚                                                                              â”‚
â”‚  Azure Data Explorer (ADX)                                                   â”‚
â”‚  âœ“ Time-series / telemetry                                                  â”‚
â”‚  âœ“ Log analytics                                                            â”‚
â”‚  âœ“ High-volume ingestion                                                    â”‚
â”‚  âœ“ Fast ad-hoc queries                                                      â”‚
â”‚                                                                              â”‚
â”‚  Azure Database for PostgreSQL                                               â”‚
â”‚  âœ“ Open source preference                                                   â”‚
â”‚  âœ“ PostGIS (geospatial)                                                     â”‚
â”‚  âœ“ Existing PostgreSQL apps                                                 â”‚
â”‚                                                                              â”‚
â”‚  Azure Cache for Redis                                                       â”‚
â”‚  âœ“ Session state                                                            â”‚
â”‚  âœ“ Caching layer                                                            â”‚
â”‚  âœ“ Pub/sub messaging                                                        â”‚
â”‚  âœ“ Rate limiting                                                            â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

*Back to [Chapter Overview](README.md)* | *Next: [Extra Resources](extra-resources.md)*

---

*Author: Michel Abboud | AI-Assisted Content | [License](../LICENSE)*
